{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import category_encoders as ce\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw, test_raw = pd.read_csv('~/Downloads/house-pricing/train.csv'), pd.read_csv('~/Downloads/house-pricing/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/amine/house-prices/helpers')\n",
    "\n",
    "from transformers.ContinuousFeaturesImputer import ContinuousFeaturesImputer\n",
    "from transformers.RareCategoriesImputer import RareCategoriesImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Street, Utilities, Condition2, RoofMatl: bad repartition\n",
    "# Alley, PoolQC: most are missing\n",
    "\n",
    "\n",
    "# MasVnrArea, BsmtFinSF1, 2ndFlrSF, LowQualFinSF, PoolArea: Had a lot of 0.0\n",
    "date_related = ['GarageYrBlt', 'MoSold', 'YrSold']\n",
    "boolean = ['CentralAir']\n",
    "target = 'SalePrice'\n",
    "to_drop = ['Id', 'PoolArea', 'PoolQC', 'YearBuilt', 'YearRemodAdd']\n",
    "\n",
    "numerical = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    "             'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    "             'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal', 'OverallCond', 'OverallQual'] + date_related\n",
    "categorical = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
    "              'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
    "              'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "              'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']  + boolean\n",
    "\n",
    "assert len(categorical )+ len(numerical) + len(to_drop) + 1 == train_raw.shape[1]\n",
    "assert set(categorical + numerical + date_related + boolean + [target] + to_drop) == set(train_raw.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_raw.copy()\n",
    "train['LivibleRatio'] = train['1stFlrSF'] / train['LotArea']\n",
    "train['HasMasVnr'] = train['MasVnrArea'] == 0\n",
    "train['BuildingAge'] = 2020 - train['YearBuilt']\n",
    "train['LastRemodling'] = 2020 - train['YearRemodAdd']\n",
    "train['HasPool'] = train['PoolArea'] > 0\n",
    "train['BuiltPercentage'] = train['1stFlrSF'] / train['LotArea']\n",
    "train['DiffBuitSold'] = train['YearBuilt'] - train['YrSold']\n",
    "train['AvrRoomSF'] = train['TotRmsAbvGrd'] / (train['1stFlrSF'] + train['2ndFlrSF'])\n",
    "train['2ndfloorPercentage'] = train['2ndFlrSF'] / train['1stFlrSF']\n",
    "train['HasBasment'] = train['TotalBsmtSF'] > 0\n",
    "train['DiffRemodBuilt'] = train['YearRemodAdd'] - train['YearBuilt']\n",
    "\n",
    "test = test_raw.copy()\n",
    "test['LivibleRatio'] = test['1stFlrSF'] / test['LotArea']\n",
    "test['HasMasVnr'] = test['MasVnrArea'] == 0\n",
    "test['BuildingAge'] = 2020 - test['YearBuilt']\n",
    "test['LastRemodling'] = 2020 - test['YearRemodAdd']\n",
    "test['HasPool'] = test['PoolArea'] > 0\n",
    "test['BuiltPercentage'] = test['1stFlrSF'] / test['LotArea']\n",
    "test['DiffBuitSold'] = test['YearBuilt'] - test['YrSold']\n",
    "test['AvrRoomSF'] = test['TotRmsAbvGrd'] / (test['1stFlrSF'] + test['2ndFlrSF'])\n",
    "test['2ndfloorPercentage'] = test['2ndFlrSF'] / test['1stFlrSF']\n",
    "test['HasBasment'] = test['TotalBsmtSF'] > 0\n",
    "test['DiffRemodBuilt'] = test['YearRemodAdd'] - test['YearBuilt']\n",
    "\n",
    "\n",
    "\n",
    "engineered = ['TotalArea', 'LivibleRatio', 'HasMasVnr', 'BuildingAge', 'LastRemodling', 'HasPool', 'BuiltPercentage', 'DiffBuitSold', 'AvrRoomSF',\n",
    "             '2ndfloorPercentage', 'HasBasment', 'DiffRemodBuilt']\n",
    "\n",
    "to_normalize = ['DiffBuitSold', 'BuildingAge', 'LastRemodling', 'DiffRemodBuilt']\n",
    "train = train.drop(columns=to_drop, axis=1)\n",
    "test = test.drop(columns=to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding discrete variables\n",
    "\n",
    "discrete = []\n",
    "for var in numerical:\n",
    "    if len(train[var].unique())<20:\n",
    "        print(var, ' values: ', train[var].unique())\n",
    "        discrete.append(var)\n",
    "        \n",
    "print('There are {} discrete variables'.format(len(discrete)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values:\n",
    "mostly_missing = list()\n",
    "treshold = 0.8\n",
    "for var in train.columns:\n",
    "    missing_prc =  train[var].isna().mean()\n",
    "    if missing_prc > treshold:\n",
    "        print(f\"{var}: {train[var].unique()}, {missing_prc}.\")\n",
    "        mostly_missing.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dist and outliers for continuous features\n",
    "continuous = [var for var in numerical if var not in discrete and var not in ['Id', 'SalePrice']]\n",
    "# continuous\n",
    "for var in continuous:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fig = sns.boxplot(y=train[var])\n",
    "    fig.set_title('')\n",
    "    fig.set_ylabel(var)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    fig = sns.distplot(train[var].dropna())\n",
    "    fig.set_ylabel('Number of houses')\n",
    "    fig.set_xlabel(var)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, train.SalePrice, test_size=0.2,\n",
    "                                                    random_state=43)\n",
    "X_train.pop(target), X_test.pop(target)\n",
    "\n",
    "y_train, y_test = np.log(y_train), np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train.copy()\n",
    "# y_train = np.log(X_train.pop(target))\n",
    "\n",
    "# X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ContinuousFeaturesImputer(drop_features=False, create_is_0=True, impute_zeros=True, drop_outliers=True).fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dealing with missing values in continuous\n",
    "# If most of the values are 0, then create seperate boolean column to indicate if 0, and replace the 0 values with median, then apply transformation\n",
    "\n",
    "for var in continuous:\n",
    "    \n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    fig = sns.boxplot(y=X_train[var])\n",
    "    fig.set_title('')\n",
    "    fig.set_ylabel(var)\n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    fig = sns.distplot(X_train[var].dropna())\n",
    "    fig.set_ylabel('Number of houses')\n",
    "    fig.set_xlabel(var)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in continuous variables\n",
    "# add variable indicating missingness + median imputation\n",
    "for df in [X_train, X_test]:\n",
    "    for var in ['LotFrontage', 'GarageYrBlt']:\n",
    "        df[var+'_NA'] = np.where(df[var].isnull(), 1, 0)\n",
    "        df[var].fillna(X_train[var].median(), inplace=True) \n",
    "\n",
    "# for df in [X_train, X_test]:\n",
    "#     df.MasVnrArea.fillna(X_train.MasVnrArea.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values in categorical data\n",
    "\n",
    "# Adding missing label\n",
    "for df in [X_train, X_test]:\n",
    "    for var in categorical:\n",
    "        df[var].fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[categorical]\n",
    "\n",
    "result = RareCategoriesImputer(0.03).fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding rare label\n",
    "treshold = 0.03\n",
    "def rare_imputation(variable):\n",
    "    # find frequent labels / discrete numbers\n",
    "    temp = X_train.groupby([variable])[variable].count()/np.float(len(X_train))\n",
    "    frequent_cat = [x for x in temp.loc[temp > treshold].index.values]\n",
    "    \n",
    "    X_train.loc[:, variable] = np.where(X_train[variable].isin(frequent_cat), X_train[variable], 'Rare')\n",
    "    X_test.loc[:, variable] = np.where(X_test[variable].isin(frequent_cat), X_test[variable], 'Rare')\n",
    "    \n",
    "# find unfrequent labels in categorical variables\n",
    "for var in categorical:\n",
    "    rare_imputation(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(result == X_train).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "encoder = ce.TargetEncoder(cols=categorical)\n",
    "encoder.fit(X_train, y_train)\n",
    "X_train, X_test = encoder.transform(X_train), encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = RobustScaler() # create an instance\n",
    "scaler.fit(X_train)\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_dist = {'objective':'reg:squarederror', 'n_estimators':1_000, 'reg_lambda': 0.1, 'max_depth':1, 'colsample_bynode': 0.5, }\n",
    "model1 = XGBRegressor(**param_dist)\n",
    "model1.fit(X_train, y_train, eval_set=[(X_train, y_train)], eval_metric=\"rmse\")\n",
    "\n",
    "model = model1\n",
    "\n",
    "rmse()\n",
    "\n",
    "sns.distplot(y_test)\n",
    "sns.distplot(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(selected=False):\n",
    "    if selected:\n",
    "        train_pred, test_pred  = model.predict(X_train[selected]), model.predict(X_test[selected])\n",
    "    else:\n",
    "        train_pred, test_pred  = model.predict(X_train), model.predict(X_test)\n",
    "        \n",
    "    train_mse, test_mse = mean_squared_error(train_pred, y_train), mean_squared_error(test_pred, y_test), \n",
    "    return np.sqrt(train_mse), np.sqrt(test_mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "rmse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def _rmse(pred, true):\n",
    "    mse = tf.keras.losses.mean_squared_error(pred, true)\n",
    "    return tf.keras.backend.sqrt(mse)\n",
    "\n",
    "\n",
    "def build_model(input_dim):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    model = Sequential()\n",
    "#     model.add(Dense(256, input_dim=input_dim, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.2), bias_regularizer=l2(0.2)))\n",
    "#     model.add(LayerNormalization())\n",
    "    model.add(Dense(128, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(64, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(32, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(16, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(8, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(4, kernel_initializer=initializer, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=initializer))\n",
    "    opt = Adam()\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[_rmse])\n",
    "    return model\n",
    "\n",
    "model = build_model(X_train.shape[1])z\n",
    "model.fit(X_train, y_train, epochs=1000, verbose=1, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# Y_train, Y_test = Y_train * std + mean, Y_test * std + mean\n",
    "rmse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort((model.predict(X_test) - y_test).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean(), y_test.max(), y_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)\n",
    "sns.distplot(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)\n",
    "sns.distplot(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': test_raw.Id, 'SalePrice': np.exp(_predict(X_test))})\n",
    "submission.to_csv(\"FirstSubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for 11.5 and 12.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = pd.DataFrame(X_train), pd.Series(y_train.reset_index(drop=True)), pd.DataFrame(X_test), pd.Series(y_test.reset_index(drop=True))\n",
    "\n",
    "\n",
    "X_train, y_train = pd.DataFrame(X_train), pd.Series(y_train.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter = (y_train > 11.5) & (y_train < 12.5)  \n",
    "# test_filter = (y_test > 11.5) & (y_test < 12.5)\n",
    "\n",
    "# X_train_fil, y_train_fil, X_test_fil, y_test_fil = X_train[train_filter], y_train[train_filter], X_test[test_filter], y_test[test_filter]\n",
    "X_train_fil, y_train_fil = X_train[train_filter], y_train[train_filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fil.shape, X_test_fil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_dist = {'objective':'reg:squarederror', 'n_estimators':1_000, 'reg_lambda': 0.1, 'max_depth':1, 'colsample_bynode': 0.2 }\n",
    "model = XGBRegressor(**param_dist)\n",
    "model.fit(X_train_fil, y_train_fil, eval_set=[(X_train_fil, y_train_fil)], eval_metric=\"rmse\")\n",
    "\n",
    "\n",
    "rmse()\n",
    "\n",
    "sns.distplot(y_test_fil)\n",
    "sns.distplot(model.predict(X_test_fil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred  = model.predict(X_train_fil), model.predict(X_test_fil)\n",
    "\n",
    "train_mse, test_mse = mean_squared_error(train_pred, y_train_fil), mean_squared_error(test_pred, y_test_fil), \n",
    "print(np.sqrt(train_mse), np.sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict(df):\n",
    "    pred_m1_train, pred_m_train = model1.predict(df), model.predict(pd.DataFrame(df))\n",
    "    \n",
    "    train_filter = (pred_m1_train > 11.5) & (pred_m1_train < 12.5)\n",
    "    \n",
    "    predictions = pred_m1_train * (~train_filter) + pred_m_train * (train_filter)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred  = _predict(X_train_fil), _predict(X_test_fil)\n",
    "\n",
    "train_mse, test_mse = mean_squared_error(train_pred, y_train_fil), mean_squared_error(test_pred, y_test_fil), \n",
    "print(np.sqrt(train_mse), np.sqrt(test_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
